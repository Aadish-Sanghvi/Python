{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M62qZc7zwlwz"
      },
      "source": [
        "## Import pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GlIV3iz-lFCi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXkRvvpkvj-t"
      },
      "source": [
        "## Step 1 – Run Basic Data Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ac1OB3vRiY8z"
      },
      "outputs": [],
      "source": [
        "def check_data_quality(df):\n",
        "    # Store initial data quality metrics\n",
        "    quality_report = {\n",
        "        'missing_values': df.isnull().sum().to_dict(),\n",
        "        'duplicates': df.duplicated().sum(),\n",
        "        'total_rows': len(df),\n",
        "        'memory_usage': df.memory_usage().sum() / 1024**2  # in MB\n",
        "    }\n",
        "    return quality_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXyrWXTGvqkY"
      },
      "source": [
        "## Step 2 – Standardize Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EyVN1pbwjz22"
      },
      "outputs": [],
      "source": [
        "def standardize_datatypes(df):\n",
        "    for column in df.columns:\n",
        "        # Try converting string dates to datetime\n",
        "        if df[column].dtype == 'object':\n",
        "            try:\n",
        "                df[column] = pd.to_datetime(df[column])\n",
        "                print(f\"Converted {column} to datetime\")\n",
        "            except ValueError:\n",
        "                # Try converting to numeric if datetime fails\n",
        "                try:\n",
        "                    df[column] = pd.to_numeric(df[column].str.replace('$', '').str.replace(',', ''))\n",
        "                    print(f\"Converted {column} to numeric\")\n",
        "                except:\n",
        "                    pass\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Sbs42VwMdi"
      },
      "source": [
        "## Step 3 – Handle Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W4lCuzTJkVRb"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def handle_missing_values(df):\n",
        "    # Handle numeric columns\n",
        "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    if len(numeric_columns) > 0:\n",
        "        num_imputer = SimpleImputer(strategy='median')\n",
        "        df[numeric_columns] = num_imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "    # Handle categorical columns\n",
        "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "    if len(categorical_columns) > 0:\n",
        "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "        df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyylQ0h1v2Ap"
      },
      "source": [
        "## Step 4 – Detect and Handle Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hic0lH3pkaYy"
      },
      "outputs": [],
      "source": [
        "def remove_outliers(df):\n",
        "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "    outliers_removed = {}\n",
        "\n",
        "    for column in numeric_columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Count outliers before removing\n",
        "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]\n",
        "\n",
        "        # Cap the values instead of removing them\n",
        "        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "        if outliers > 0:\n",
        "            outliers_removed[column] = outliers\n",
        "\n",
        "    return df, outliers_removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCV0vKBcwVVB"
      },
      "source": [
        "## Step 5 – Validate the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5mCT72R8ke2r"
      },
      "outputs": [],
      "source": [
        "def validate_cleaning(df, original_shape, cleaning_report):\n",
        "    validation_results = {\n",
        "        'rows_remaining': len(df),\n",
        "        'missing_values_remaining': df.isnull().sum().sum(),\n",
        "        'duplicates_remaining': df.duplicated().sum(),\n",
        "        'data_loss_percentage': (1 - len(df)/original_shape[0]) * 100\n",
        "    }\n",
        "\n",
        "    # Add validation results to the cleaning report\n",
        "    cleaning_report['validation'] = validation_results\n",
        "    return cleaning_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W46kva14wX7B"
      },
      "source": [
        "## Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ybHCRL8Dkmhz"
      },
      "outputs": [],
      "source": [
        "def automated_cleaning_pipeline(df):\n",
        "    # Store original shape for reporting\n",
        "    original_shape = df.shape\n",
        "\n",
        "    # Initialize cleaning report\n",
        "    cleaning_report = {}\n",
        "\n",
        "    # Execute each step and collect metrics\n",
        "    cleaning_report['initial_quality'] = check_data_quality(df)\n",
        "\n",
        "    df = standardize_datatypes(df)\n",
        "    df = handle_missing_values(df)\n",
        "    df, outliers = remove_outliers(df)\n",
        "    cleaning_report['outliers_removed'] = outliers\n",
        "\n",
        "    # Validate and finalize report\n",
        "    cleaning_report = validate_cleaning(df, original_shape, cleaning_report)\n",
        "\n",
        "    return df, cleaning_report\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
